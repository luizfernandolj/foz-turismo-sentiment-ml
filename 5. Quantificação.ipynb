{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03713c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlquantify.methods import *\n",
    "import mlquantify as mq\n",
    "from mlquantify.evaluation.protocol import APP\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565862a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bourbon.csv',\n",
       " 'continental.csv',\n",
       " 'foz_plaza.csv',\n",
       " 'nadai.csv',\n",
       " 'taroba.csv',\n",
       " 'viale_cataratas.csv',\n",
       " 'viale_tower.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = os.listdir('datasets com score')\n",
    "FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b341d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelProtocol(APP):\n",
    "    def __init__(self,     \n",
    "                 models, \n",
    "                 batch_size,\n",
    "                 learner = None, \n",
    "                 n_prevs = 50,\n",
    "                 n_iterations = 3,\n",
    "                 n_jobs = -1,\n",
    "                 random_state = 32,\n",
    "                 verbose = False,\n",
    "                 return_type = \"predictions\",\n",
    "                 measures = None):\n",
    "        \n",
    "        super().__init__(models=models,\n",
    "                         batch_size=batch_size,\n",
    "                         learner=learner,\n",
    "                         n_jobs=n_jobs,\n",
    "                         random_state=random_state,\n",
    "                         verbose=verbose,\n",
    "                         return_type=return_type,\n",
    "                         measures=measures)\n",
    "        self.n_prevs = n_prevs\n",
    "        self.batch_size = batch_size if isinstance(batch_size, list) else [batch_size]\n",
    "        self.n_prevs = n_prevs\n",
    "        self.n_iterations = n_iterations\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train, train_scores):\n",
    "        args = ((model, X_train, y_train, train_scores) for model in self.models)\n",
    "        \n",
    "        wrapper = tqdm if self.verbose else lambda x, **kwargs: x\n",
    "    \n",
    "        self.models = Parallel(n_jobs=self.n_jobs)(  # Parallel processing of models\n",
    "            delayed(self._delayed_fit)(*arg) for arg in wrapper(args, desc=\"Fitting models\", total=len(self.models))\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _predict(self, iteration, X, y, model, prev, batch_size, verbose):\n",
    "        model_name = model.__class__.__name__\n",
    "        if model_name == \"Ensemble\" and isinstance(model.base_quantifier, Quantifier):\n",
    "            model_name = f\"{model.__class__.__name__}_{model.base_quantifier.__class__.__name__}_{model.size}\"\n",
    "        \n",
    "        X_sample, _ = self._new_sample(X, y, prev, batch_size)\n",
    "          \n",
    "        posteriors_test = pd.DataFrame({\n",
    "            '0': abs(1 - X_sample[\"score\"]),\n",
    "            '1': X_sample[\"score\"]\n",
    "        })\n",
    "        \n",
    "        X_sample = X_sample.drop(columns=[\"score\"])\n",
    "        \n",
    "        y_pred = (posteriors_test.iloc[:, 1] > 0.5).astype(int)\n",
    "        \n",
    "        \n",
    "        mq.set_arguments(posteriors_test=posteriors_test,\n",
    "                      y_pred=y_pred)\n",
    "        \n",
    "        prev_pred = np.asarray(list(model.predict(X_sample).values()))\n",
    "        \n",
    "        return (iteration+1, model_name, prev, prev_pred, batch_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _delayed_fit(self, model, X_train, y_train, train_scores):\n",
    "        model_name = model.__class__.__name__\n",
    "        if model_name == \"Ensemble\" and isinstance(model.base_quantifier, Quantifier):\n",
    "            model_name = f\"{model.__class__.__name__}_{model.base_quantifier.__class__.__name__}_{model.size}\"\n",
    "\n",
    "        y_train_pred = (train_scores.iloc[:, 1] > 0.5).astype(int)\n",
    "\n",
    "        mq.set_arguments(posteriors_train=train_scores,\n",
    "                        y_labels=y_train,\n",
    "                        y_pred_train=y_train_pred\n",
    "                        )\n",
    "        model = model.fit(X=X_train, y=y_train)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8c251",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing aspect 1/5 -> Atendimento da equipe\n",
      "Train samples: 367, Test samples: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running APP:   1%|â–         | 54/4275 [00:00<00:21, 200.40it/s]\n",
      "c:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\utils\\method.py:8: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"\"\"\n",
      "c:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\utils\\method.py:43: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"\"\"\n",
      "c:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\utils\\method.py:79: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"\"\"\n",
      "c:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\utils\\method.py:116: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     40\u001b[39m hotel_protocol = HotelProtocol(models=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m                             n_prevs=\u001b[32m5\u001b[39m,\n\u001b[32m     42\u001b[39m                             batch_size=batch_sizes,\n\u001b[32m     43\u001b[39m                             return_type=\u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m                             measures=[\u001b[33m\"\u001b[39m\u001b[33mmae\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrae\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     46\u001b[39m hotel_protocol.fit(X_train, y_train, train_scores=train_scores)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m table = \u001b[43mhotel_protocol\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m table[\u001b[33m\"\u001b[39m\u001b[33mhotel\u001b[39m\u001b[33m\"\u001b[39m] = name\n\u001b[32m     51\u001b[39m table[\u001b[33m\"\u001b[39m\u001b[33maspect\u001b[39m\u001b[33m\"\u001b[39m] = aspect\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\evaluation\\protocol.py:266\u001b[39m, in \u001b[36mProtocol.predict\u001b[39m\u001b[34m(self, X_test, y_test)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test: np.ndarray, y_test: np.ndarray) -> Any:\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predicts the prevalence for the test set.\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m        Predictions for the test set. Can be a table or a tuple with the quantifier names, real prevalence, and predicted prevalence.\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     predictions_df = pd.DataFrame(predictions, columns=\u001b[38;5;28mself\u001b[39m.columns)\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_type == \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\evaluation\\protocol.py:495\u001b[39m, in \u001b[36mAPP.predict_protocol\u001b[39m\u001b[34m(self, X_test, y_test)\u001b[39m\n\u001b[32m    493\u001b[39m predictions = []\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tqdm(args, desc=\u001b[33m\"\u001b[39m\u001b[33mRunning APP\u001b[39m\u001b[33m\"\u001b[39m, total=size):\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     predictions.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mHotelProtocol._predict\u001b[39m\u001b[34m(self, iteration, X, y, model, prev, batch_size, verbose)\u001b[39m\n\u001b[32m     53\u001b[39m y_pred = (posteriors_test.iloc[:, \u001b[32m1\u001b[39m] > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     56\u001b[39m mq.set_arguments(posteriors_test=posteriors_test,\n\u001b[32m     57\u001b[39m               y_pred=y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m prev_pred = np.asarray(\u001b[38;5;28mlist\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m)\u001b[49m.values()))\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (iteration+\u001b[32m1\u001b[39m, model_name, prev, prev_pred, batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\base.py:514\u001b[39m, in \u001b[36mNonAggregativeQuantifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    495\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Predict class prevalences for the given data.\u001b[39;00m\n\u001b[32m    496\u001b[39m \n\u001b[32m    497\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    511\u001b[39m \u001b[33;03m  dictionary of class prevalences.\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary_data \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_multiclass:\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     prevalences = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m normalize_prevalence(prevalences, \u001b[38;5;28mself\u001b[39m.classes)\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# One-vs-all approach\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\methods\\non_aggregative.py:120\u001b[39m, in \u001b[36mHDx._predict_method\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X.shape[\u001b[32m1\u001b[39m]):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m bins \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bins_size:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         dist_feature_pos = \u001b[43mgetHist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m         dist_feature_neg = getHist(\u001b[38;5;28mself\u001b[39m.neg_features[:, i], bins)\n\u001b[32m    122\u001b[39m         dist_feature_test = getHist(X[:, i], bins)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Luiz Fernando\\Projects\\ic-hotel\\.venv\\Lib\\site-packages\\mlquantify\\utils\\method.py:258\u001b[39m, in \u001b[36mgetHist\u001b[39m\u001b[34m(scores, nbins)\u001b[39m\n\u001b[32m    256\u001b[39m re = np.repeat(\u001b[32m1\u001b[39m / (\u001b[38;5;28mlen\u001b[39m(breaks) - \u001b[32m1\u001b[39m), (\u001b[38;5;28mlen\u001b[39m(breaks) - \u001b[32m1\u001b[39m))\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(breaks)):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     re[i - \u001b[32m1\u001b[39m] = (re[i - \u001b[32m1\u001b[39m] + \u001b[38;5;28mlen\u001b[39m(np.where((\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbreaks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m) & (scores < breaks[i]))[\u001b[32m0\u001b[39m])) / (\u001b[38;5;28mlen\u001b[39m(scores) + \u001b[32m1\u001b[39m)\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m re\n",
      "\u001b[31mTypeError\u001b[39m: '>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "final_table = pd.DataFrame()\n",
    "\n",
    "mq.methods.METHODS.pop(\"ENSEMBLE\", None)\n",
    "mq.methods.METHODS.pop(\"DySsyn\", None)\n",
    "# mq.methods.METHODS.pop(\"HDx\", None)\n",
    "# mq.methods.METHODS.pop(\"GAC\", None)\n",
    "\n",
    "for file in FILES:\n",
    "    name = file.split('.')[0]\n",
    "    dataset = pd.read_csv(f\"datasets com score/{file}\")\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    dataset.sort_values('date', inplace=True)\n",
    "    i = 0\n",
    "    aspects = dataset[\"aspect\"].unique()\n",
    "    for aspect in aspects:\n",
    "        print(f\"Processing aspect {i+1}/{len(aspects)} -> {aspect}\")\n",
    "        i = i + 1\n",
    "        df = dataset[dataset[\"aspect\"] == aspect]\n",
    "        \n",
    "        if df['class'].value_counts().min() < 2:\n",
    "            train_df, test_df = train_test_split(df, test_size=0.3, random_state=32)\n",
    "        else:\n",
    "            train_df, test_df = train_test_split(df, test_size=0.3, stratify=df['class'], random_state=32)\n",
    "\n",
    "        X_train = train_df.drop(['class', 'score', 'date'], axis=1)\n",
    "        y_train = train_df['class']\n",
    "        X_test = test_df.drop(['class', 'date'], axis=1)\n",
    "        y_test = test_df['class']\n",
    "\n",
    "        print(f\"Train samples: {len(y_train)}, Test samples: {len(y_test)}\")\n",
    "\n",
    "        train_scores = pd.DataFrame({\n",
    "            '0': abs(1 - train_df[\"score\"]),\n",
    "            '1': train_df[\"score\"]\n",
    "        })\n",
    "\n",
    "        batch_sizes = list(np.linspace(25, len(y_test), 5).astype(int))\n",
    "\n",
    "        mq.ARGUMENTS_SETTED = True\n",
    "        hotel_protocol = HotelProtocol(models=\"all\",\n",
    "                                    n_prevs=50,\n",
    "                                    batch_size=batch_sizes,\n",
    "                                    return_type=\"table\",\n",
    "                                    measures=[\"mae\", \"rae\"])\n",
    "        \n",
    "        hotel_protocol.fit(X_train, y_train, train_scores=train_scores)\n",
    "\n",
    "        table = hotel_protocol.predict(X_test, y_test)\n",
    "        \n",
    "        table[\"hotel\"] = name\n",
    "        table[\"aspect\"] = aspect\n",
    "\n",
    "        final_table = pd.concat([final_table, table], ignore_index=True)\n",
    "\n",
    "final_table.to_csv(\"quantification_results.csv\", index=False)\n",
    "final_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f005c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
